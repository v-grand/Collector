{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v-grand/Collector/blob/main/Crypto_ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR51tGs7SLDz"
      },
      "source": [
        "# Instal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGsVKO5RSEZj",
        "outputId": "823b5f07-bd35-489f-d0c9-78f28c3cffdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=aead026da6e278582b1676745bbc98be13debe4c41bf3ddbd2f0ba0e54ee42bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/67/4f/8a9f252836e053e532c6587a3230bc72a4deb16b03a829610b\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n",
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.10b0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mplfinance) (3.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mplfinance) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mplfinance) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->mplfinance) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mplfinance) (1.17.0)\n",
            "Downloading mplfinance-0.12.10b0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.10b0\n"
          ]
        }
      ],
      "source": [
        "!pip install ta\n",
        "!pip install mplfinance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty6MuIn8SG5y"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHiUOYmkRvTm",
        "outputId": "3281afaa-9c2b-475e-81d2-fdd7b1e87e1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "'''\n",
        "%pip install prophet\n",
        "\n",
        "'''\n",
        "import requests\n",
        "import urllib\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import ta\n",
        "from typing import Tuple\n",
        "import yfinance as yf\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "#from tensorflow.keras.models import load_model\n",
        "\n",
        "from prophet import Prophet\n",
        "\n",
        "# Подключение Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jd_vK0IScxx"
      },
      "source": [
        "# Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CKc3yuyaSfOt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "8c5d416b-d733-4021-d036-99c21a7ab48e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DataFrame' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1123600b7558>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_na\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'BTC-USD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'60d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'5m'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mN_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterval_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataFrame' is not defined"
          ]
        }
      ],
      "source": [
        "def prep_data(drop_na:bool = True, ticker='BTC-USD', period='60d', interval_='5m') -> DataFrame:\n",
        "\n",
        "    N_pred=3\n",
        "\n",
        "    data = yf.download(ticker, period=period, interval=interval_)\n",
        "\n",
        "\n",
        "    data.drop(columns=['Adj Close','Volume'], inplace=True)\n",
        "\n",
        "    data['NextOpen'] = data['Open'].shift(-1)\n",
        "    data['NextHigh'] = data['High'].shift(-1)\n",
        "    data['NextLow'] = data['Low'].shift(-1)\n",
        "    data['NextClose'] = data['Close'].shift(-1)\n",
        "\n",
        "\n",
        "    for i in range(1, N_pred):\n",
        "      data[f'PrevOpen_bar{i}'] = data['Open'].shift(i)\n",
        "      data[f'PrevHigh_bar{i}'] = data['High'].shift(i)\n",
        "      data[f'PrevLow_bar{i}'] = data['Low'].shift(i)\n",
        "      data[f'PrevClose_bar{i}'] = data['Close'].shift(i)\n",
        "\n",
        "    data = data.iloc[N_pred:]\n",
        "\n",
        "\n",
        "    # Drop NaN values\n",
        "    if(drop_na):\n",
        "        data.dropna(inplace=True)\n",
        "\n",
        "    data.reset_index(inplace=True)\n",
        "\n",
        "    if data.empty:\n",
        "      print(f'No data found for {ticker}')\n",
        "      return None\n",
        "    else:\n",
        "\n",
        "      if 'Date' in data.columns:\n",
        "        last_date_value= data['Date'].iloc[-1]\n",
        "        first_data_value=data['Date'].iloc[0]\n",
        "        print(f'   {ticker} load at {first_data_value} to {last_date_value} interval {interval_}')\n",
        "\n",
        "      elif 'Datetime' in data.columns:\n",
        "        last_date_value= data['Datetime'].iloc[-1]\n",
        "        first_data_value=data['Datetime'].iloc[0]\n",
        "        print(f'   {ticker} load at {first_data_value} to {last_date_value} interval {interval_}')\n",
        "\n",
        "    data.rename(columns=lambda x: f'{x}_{interval_}', inplace=True)\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QF_XxXImUTJu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "eb4c8d9b-bec7-4b25-fdc6-0198a48a21d3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DataFrame' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cd99b654c4ad>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mscale_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Prepare target variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataFrame' is not defined"
          ]
        }
      ],
      "source": [
        "def scale_data(data:DataFrame, columns_x, columns_y) -> Tuple[MinMaxScaler, np.ndarray, np.ndarray]:\n",
        "\n",
        "    # Prepare target variable\n",
        "    y = data[columns_y].values\n",
        "    X = data [columns_x]\n",
        "\n",
        "    # Scale features\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    y_scaled = scaler.fit_transform(y.reshape(-1, 1)).reshape(-1)\n",
        "\n",
        "    return scaler, X_scaled, y_scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3zJ-cATobI8"
      },
      "source": [
        "#3mo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYwMKzJeR-4s",
        "outputId": "8bda3468-d036-4474-f9cc-cc0b20f978f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   XRP-USD load at 2018-08-01 00:00:00+00:00 to 2024-08-01 00:00:00+00:00 interval 3mo\n",
            "Price               Ticker     \n",
            "Date_3mo            _3mo           2024-08-01 00:00:00+00:00\n",
            "Close_3mo           XRP-USD_3mo                     0.509237\n",
            "High_3mo            XRP-USD_3mo                     0.662206\n",
            "Low_3mo             XRP-USD_3mo                     0.433492\n",
            "Open_3mo            XRP-USD_3mo                     0.623934\n",
            "NextOpen_3mo        _3mo                            0.509237\n",
            "NextHigh_3mo        _3mo                            0.541252\n",
            "NextLow_3mo         _3mo                            0.493652\n",
            "NextClose_3mo       _3mo                            0.535262\n",
            "PrevOpen_bar1_3mo   _3mo                            0.500062\n",
            "PrevHigh_bar1_3mo   _3mo                            0.657911\n",
            "PrevLow_bar1_3mo    _3mo                            0.391139\n",
            "PrevClose_bar1_3mo  _3mo                            0.623939\n",
            "PrevOpen_bar2_3mo   _3mo                            0.503176\n",
            "PrevHigh_bar2_3mo   _3mo                            0.742126\n",
            "PrevLow_bar2_3mo    _3mo                            0.433634\n",
            "PrevClose_bar2_3mo  _3mo                            0.500065\n",
            "Name: 24, dtype: object\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "interval_ = '3mo'\n",
        "period_ = 'max'  # или другой поддерживаемый период, например '10y' для последних 10 лет\n",
        "\n",
        "ticker_3mo = 'XRP-USD'\n",
        "data_3mo = prep_data(drop_na=True, ticker=ticker_3mo, period=period_, interval_=interval_)\n",
        "\n",
        "# Проверяем, что данные загружены корректно\n",
        "if data_3mo is not None and not data_3mo.empty:\n",
        "    # Последняя строка\n",
        "    last_row = data_3mo.iloc[-1]\n",
        "    print(last_row)\n",
        "else:\n",
        "    print(\"No data found for\", ticker_3mo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "K9XVj4l8oGkP",
        "outputId": "98da050f-daf5-4686-99a0-c6101fa7c3c1"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-721d04125e3a>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolumns_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'NextClose_3mo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# ['NextOpen_3mo', 'NextHigh_3mo', 'NextLow_3mo', 'NextClose_3mo']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_3mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-cd99b654c4ad>\u001b[0m in \u001b[0;36mscale_data\u001b[0;34m(data, columns_x, columns_y)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Prepare target variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "columns_x = ['Open_3mo', 'High_3mo', 'Low_3mo', 'Close_3mo',\n",
        "           'PrevOpen_bar1_3mo', 'PrevHigh_bar1_3mo', 'PrevLow_bar1_3mo',\n",
        "           'PrevClose_bar1_3mo', 'PrevOpen_bar2_3mo', 'PrevHigh_bar2_3mo',\n",
        "           'PrevLow_bar2_3mo', 'PrevClose_bar2_3mo']\n",
        "columns_y = ['NextClose_3mo']\n",
        "# ['NextOpen_3mo', 'NextHigh_3mo', 'NextLow_3mo', 'NextClose_3mo']\n",
        "scaler, X_scaled, y_scaled = scale_data(data_3mo, columns_x, columns_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEM_R9BGqBf4"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "model_name = \"/content/drive/My Drive/High_random_forest.joblib\"\n",
        "    # Random Forest model\n",
        "model_High = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model_High.fit(X_train, y_train)\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "joblib.dump(model_High, model_name)\n",
        "\n",
        "    # Predict the prices\n",
        "predicted_prices = model_High.predict(X_test)\n",
        "\n",
        "    # Evaluate\n",
        "mse = mean_squared_error(y_test, predicted_prices)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "#feature_importance_high = model_High.feature_importances_\n",
        "#feature_df_high = pd.DataFrame({'Feature': data_x.columns, 'Importance': feature_importance_high})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyclTq1xGGQ-"
      },
      "outputs": [],
      "source": [
        "# developer: Foundry Digital\n",
        "# Copyright © 2023 Foundry Digital\n",
        "\n",
        "# Import necessary modules to use for model creation - can be downloaded using pip\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "def create_and_save_base_model_lstm(scaler:MinMaxScaler, X_scaled:np.ndarray, y_scaled:np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Base model that can be created for predicting the S&P 500 close price\n",
        "\n",
        "    The function creates a base model, given a scaler, inputs and outputs, and\n",
        "    stores the model weights as a .h5 file in the mining_models/ folder. The model\n",
        "    architecture and model name given now is a placeholder, can (and should)\n",
        "    be changed by miners to build more robust models.\n",
        "\n",
        "    Input:\n",
        "        :param scaler: The scaler used to scale the inputs during model training process\n",
        "        :type scaler: sklearn.preprocessing.MinMaxScaler\n",
        "\n",
        "        :param X_scaled: The already scaled input data that will be used by the model to train and test\n",
        "        :type X_scaled: np.ndarray\n",
        "\n",
        "        :param y_scaled: The already scaled output data that will be used by the model to train and test\n",
        "        :type y_scaled: np.ndarray\n",
        "\n",
        "    Output:\n",
        "        :returns: The MSE of the model on the test data\n",
        "        :rtype: float\n",
        "    \"\"\"\n",
        "    model_name = \"mining_models/base_lstm\"\n",
        "\n",
        "    # Reshape input for LSTM\n",
        "    X_scaled = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
        "\n",
        "    # Split data into training and testing\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "    # LSTM model - all hyperparameters are baseline params - should be changed according to your required\n",
        "    # architecture. LSTMs are also not the only way to do this, can be done using any algo deemed fit by\n",
        "    # the creators of the miner.\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X_scaled.shape[1], X_scaled.shape[2])))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(units=50, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "    model.save(f'{model_name}.h5')\n",
        "\n",
        "    # Predict the prices - this is just for a local test, this prediction just allows\n",
        "    # miners to assess the performance of their models on real data.\n",
        "    predicted_prices = model.predict(X_test)\n",
        "\n",
        "    # Rescale back to original range\n",
        "    predicted_prices = scaler.inverse_transform(predicted_prices)\n",
        "    y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "    # Evaluate\n",
        "    mse = mean_squared_error(y_test_rescaled, predicted_prices)\n",
        "    print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "    return mse\n",
        "\n",
        "def create_and_save_base_model_regression(scaler:MinMaxScaler, X_scaled:np.ndarray, y_scaled:np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Base model that can be created for predicting the S&P 500 close price\n",
        "\n",
        "    The function creates a base model, given a scaler, inputs and outputs, and\n",
        "    stores the model weights as a .h5 file in the mining_models/ folder. The model\n",
        "    architecture and model name given now is a placeholder, can (and should)\n",
        "    be changed by miners to build more robust models.\n",
        "\n",
        "    Input:\n",
        "        :param scaler: The scaler used to scale the inputs during model training process\n",
        "        :type scaler: sklearn.preprocessing.MinMaxScaler\n",
        "\n",
        "        :param X_scaled: The already scaled input data that will be used by the model to train and test\n",
        "        :type X_scaled: np.ndarray\n",
        "\n",
        "        :param y_scaled: The already scaled output data that will be used by the model to train and test\n",
        "        :type y_scaled: np.ndarray\n",
        "\n",
        "    Output:\n",
        "        :returns: The MSE of the model on the test data\n",
        "        :rtype: float\n",
        "    \"\"\"\n",
        "    model_name = \"mining_models/base_linear_regression\"\n",
        "\n",
        "    # Split data into training and testing\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "    # LSTM model - all hyperparameters are baseline params - should be changed according to your required\n",
        "    # architecture. LSTMs are also not the only way to do this, can be done using any algo deemed fit by\n",
        "    # the creators of the miner.\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    '''with h5py.File(f'{model_name}.h5', 'w') as hf:\n",
        "        hf.create_dataset('coefficients', data=model.coef_)\n",
        "        hf.create_dataset('intercept', data=model.intercept_)'''\n",
        "    joblib.dump(model, f\"{model_name}.joblib\")\n",
        "\n",
        "    # Predict the prices - this is just for a local test, this prediction just allows\n",
        "    # miners to assess the performance of their models on real data.\n",
        "    predicted_prices = model.predict(X_test)\n",
        "\n",
        "    # Rescale back to original range\n",
        "    predicted_prices = scaler.inverse_transform(predicted_prices.reshape(-1, 1))\n",
        "    y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "    # Evaluate\n",
        "    mse = mean_squared_error(y_test_rescaled, predicted_prices)\n",
        "    print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "    return mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGFs8CaCR5x4"
      },
      "source": [
        "# Spread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zao2o3xcz6b",
        "outputId": "e69eb6cc-b1b7-4509-e877-5d7ec95dacfe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ATOM-USD load at 2019-03-17 00:00:00 to 2025-01-02 00:00:00 interval 1d\n",
            "   XRP-USD load at 2017-11-12 00:00:00 to 2025-01-02 00:00:00 interval 1d\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "interval_='1d'\n",
        "period_='300d'\n",
        "\n",
        "ticker_2='XRP-USD'\n",
        "ticker_1='ATOM-USD'\n",
        "K_1=1\n",
        "K_2=20\n",
        "\n",
        "data_1 = prep_data(drop_na=True, ticker=ticker_1, period=period_, interval_=interval_)\n",
        "#print(data_1.shape)\n",
        "\n",
        "data_2 = prep_data(drop_na=True, ticker=ticker_2, period=period_, interval_=interval_)\n",
        "#print(data_2.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "l2gAEvZjwWrZ",
        "outputId": "7643398c-086c-4f8a-a7c9-2b342f5c0e2f"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e9a213af46ab>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Объединяем датасеты по столбцу Datetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcombined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Datetime_1h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK_1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close_1h_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mK_2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close_1h_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#combined_df.info()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mleft_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mright_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cross\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_validate_operand\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2692\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m   2693\u001b[0m             \u001b[0;34mf\"Can only merge Series or DataFrame objects, a {type(obj)} was passed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         )\n",
            "\u001b[0;31mTypeError\u001b[0m: Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed"
          ]
        }
      ],
      "source": [
        "# Объединяем датасеты по столбцу Datetime\n",
        "combined_df = pd.merge(data_1, data_2, on='Datetime_1h', how='inner')\n",
        "\n",
        "combined_df['Close']=K_1*combined_df['Close_1h_x']-K_2*combined_df['Close_1h_y']\n",
        "#combined_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxVIdjAPZoCg"
      },
      "outputs": [],
      "source": [
        "from prophet import Prophet\n",
        "\n",
        "dp_ds = combined_df[['Datetime_1h', 'Close']].copy()\n",
        "dp_ds['Datetime_1h'] = dp_ds['Datetime_1h'].dt.tz_localize(None)\n",
        "\n",
        "# Подготовка данных для Prophet\n",
        "dp_ds = dp_ds.rename(columns={'Datetime_1h': 'ds', 'Close': 'y'})\n",
        "\n",
        "\n",
        "model = Prophet(\n",
        "    growth='linear',\n",
        "    changepoint_range=0.8,\n",
        "    seasonality_mode='additive',\n",
        "    seasonality_prior_scale=10.0,\n",
        "    holidays_prior_scale=10.0,\n",
        "    changepoint_prior_scale=0.05,\n",
        "    interval_width=0.8,\n",
        "    uncertainty_samples=10\n",
        ")\n",
        "# Продолжаем обучение и прогнозирование\n",
        "\n",
        "model.fit(dp_ds)\n",
        "\n",
        "# Создание будущего DataFrame для прогнозов\n",
        "future = model.make_future_dataframe(periods=30)  # Прогноз на 30 дней вперед\n",
        "\n",
        "# Получение прогнозов\n",
        "forecast = model.predict(future)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_P0HLx4rcRp"
      },
      "outputs": [],
      "source": [
        "# Построение графика прогнозов\n",
        "fig = model.plot( forecast.iloc[-100:])\n",
        "plt.xlabel(f'Date')\n",
        "plt.ylabel('Quote')\n",
        "plt.title(f'{ticker_1}x{K_1} and {ticker_2}x{K_2}')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AR51tGs7SLDz",
        "3jd_vK0IScxx",
        "k3zJ-cATobI8"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOovE/FSKneTZvaUWExcZn0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}